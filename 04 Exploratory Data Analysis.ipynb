{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis with Pandas\n",
    "\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video tutorials: http://www.dataschool.io/easier-data-analysis-with-pandas/\n",
    "\n",
    "A lot of the content of this notebook is based on Jake VanderPlas' excellent Python Data Science Handbook: https://jakevdp.github.io/PythonDataScienceHandbook/\n",
    "\n",
    "Many exercises are adapted from https://github.com/ajcr/100-pandas-puzzles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy - the Foundation of Data Science in Python\n",
    "\n",
    "Data science is largely about the efficient manipulation of collections of numbers, so to support effective data science a language needs a way to do this. In Python this is done through the NumPy libary, which are much more memory- and computation-efficient than the built-in lists in Python.\n",
    "\n",
    "Python dicts are suboptimal for several reasons:\n",
    "\n",
    "* they are heterogeneous\n",
    "* even when storing numbers, these numbers are objects (as Python is a pure OOPL), and so are more than just (say) int32 or int64's like in C/C++; they have reference counts, type info, size info, and the actual data\n",
    "\n",
    "Python offers an array type which is homogeneous which improves om lists as far as storage goes, but offers limited operations on that data.\n",
    "\n",
    "NumPy bridges the gap, offering both efficient storage of homogeneous data in single or multi-dimensional arrays, and a rich set of operations on that data.\n",
    "\n",
    "In this section we will cover some of the basics of NumPy, but our focus will be mostly on Pandas, a library built on top of NumPy that is particularly well-suited to manipulating tabular data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create one dimensional NumPy array from a list\n",
    "a = np.array([1, 2, 3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append a value\n",
    "b = a\n",
    "a = np.append(a, 4)  # Note that this makes a copy; the original array is not affected\n",
    "print(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the shape and # of elements\n",
    "print(np.shape(a))\n",
    "print(np.size(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Index and slice\n",
    "print(f'Second element of a is {a[1]}')\n",
    "print(f'Last element of a is {a[-1]}')\n",
    "print(f'Middle two elements of a are {a[1:3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a 2-D array from a list of lists\n",
    "b = np.array([[1,2,3],\n",
    "              [4,5,6],\n",
    "              [7,8,9]])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the shape, # of elements, and # of dimensions\n",
    "print(np.shape(b))\n",
    "print(np.size(b))\n",
    "print(np.ndim(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the first row of b; these are equivalent\n",
    "print(b[0]) \n",
    "print(b[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the first column of b\n",
    "print(b[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a subsection of b, from 1,1 through 2,2 (i.e. before 3,3)\n",
    "print(b[1:3,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an array of zeros of length n\n",
    "np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an array of 1s\n",
    "np.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creat an array of 10 random integers between 1 and 100\n",
    "np.random.randint(1,100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create linearly spaced array of 5 values from 0 to 100\n",
    "np.linspace(0, 100, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UFuncs\n",
    "\n",
    "NumPy supports highly efficient operations on arrays called UFuncs (Universal Functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(b)  # Get the mean of all the elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.power(b, 2)  # Raise every element to second power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the details on UFuncs here: https://docs.scipy.org/doc/numpy-1.13.0/reference/ufuncs.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Series\n",
    "\n",
    "A Pandas Series is a one-dimensional array of indexed data. It wraps a sequence of values and a sequence of indices. The values are a NumPy array, while the indices are an instance of a pd.Index object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.Series([1, 4, 9, 16, 25])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can show the first few lines with `.head()`. The argument, if omitted, defaults to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal indexing and slicing operations are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where NumPy arrays have implicit integer sequence indices, Pandas indices are explicit and need not be integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.Series([1, 4, 9, 16, 25], index=['square of 1', 'square of 2', 'square of 3', 'square of 4', 'square of 5'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['square of 3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a Series is a lot like a Python dict (with additional slicing), and we can construct one from a Python dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series({'square of 1':1, 'square of 2':4, 'square of 3':9, 'square of 4':16, 'square of 5':25})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Given the list below, create a Series that has the list as both the index and the values, and then display the first 3 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex1 = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 1: Put your code here.\n",
    "# Uncomment and run the %load magic for a sample solution.\n",
    "# %load ex04-01.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of dict-style operations work on a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reconstruct the Series\n",
    "data = pd.Series([1, 4, 9, 16, 25], index=['square of 1', 'square of 2', 'square of 3', 'square of 4', 'square of 5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'square of 5' in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.items()  # Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(data.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.values  # Unlike Python dict, this is not the same - it's an array, not a function returning an interable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['square of 6'] = 36  # We can add new entries\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['square of 6'] = -1  # And change existing values\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del data['square of 6']  # And delete a value\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of functions available on a series, like `.sum()`, `.median()`, `.mode()`, and `.mean()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series also behaves a lot like a list. We saw some indexing and slicing earlier. This can be done on non-numeric indexes too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['square of 2': 'square of 4']  # This can be confusing as it INCLUDES the final value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['square of 2': 'cube of 4']  # Be aware - a missing key will result in empty results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Delete the row 'k' from the earlier series, then display the rows from 'f' through 'l'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2: put your code here\n",
    "# %load ex04-02.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DataFrames\n",
    "\n",
    "A DataFrame is like a dictionary that maps column names to Series objects that share the same index.\n",
    "\n",
    "Read the sentence above again and make sure it makes sense to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = pd.Series(['Alice', 'Bob', 'Carol'])\n",
    "phones = pd.Series(['555-123-4567', '555-987-6543', '555-245-6789'])\n",
    "\n",
    "df = pd.DataFrame({'Name': names, 'Phone': phones})  # 'Name' and 'Phone' are the column names\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.index  # Like Series, DataFrame has an index for rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns  # DataFrame also has an index for columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Name']  # Acts similar to dictionary; returns Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.Name  # You can also access columns like this, with dot-notation.\n",
    "# Occasionally this breaks if there is a name conflcit with a UFunc, like 'count'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can add new columns. Later we'll see how to do this as a function of existing columns\n",
    "df['Closed'] = True\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use .describe() to get summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to construct a DataFrame. For example, from a Series or dictionary of Series, from a list of Python dicts, or from a 2-D NumPy array. There are also utility functions to read data from disk into a DataFrame, e.g. from a .csv file or an Excel spreadsheet. We'll cover some of these later.\n",
    "\n",
    "Many DataFrame operations take an `axis` argument which defaults to zero. This specifies whether we want to apply the operation by rows (axis=0) or by columns (axis=1).\n",
    "\n",
    "### Exercise 3\n",
    "\n",
    "Create a DataFrame from the dictionary below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {'animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],\n",
    "        'age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3],\n",
    "        'visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment and run next line for solutions\n",
    "# %load ex04-03.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put your code to create the DataFrame here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a summary of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the sum of all visits (the total number of visits).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexes\n",
    "\n",
    "The Pandas Index can be thought of as an immutable ordered multiset (multiset as indices need not be unique). The immutability makes it safe to share an index between multiple columns of a DataFrame. The set-like properties are useful for things like joins (a join is like an intersection between Indexes). Let's look at some example operations to get more familiar with how they work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's create two Indexes for experimentation\n",
    "\n",
    "i1 = pd.Index([1, 3, 5, 7, 9])\n",
    "i2 = pd.Index([2, 3, 5, 7, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i1[2]  # We can index like an array with []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i1[2:5]  # And slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i1 & i2  # Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i1 | i2  # Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i1 ^ i2  # Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series and DataFrames have an explicit Index but they also have an implicit index like a list. If the Index uses integer values things can get confusing. In such cases it is good to be explicit; there are attributes for this:\n",
    "\n",
    "- `.loc` references the explicit Index\n",
    "- `.iloc` references the implicit Index\n",
    "\n",
    "The Python way is \"explicit is better than implicit\" so when indexing/slicing it is better to use these. The example below illustrates the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: explicit index starts at 1; implicit index starts at 0\n",
    "s = pd.Series(['first', 'second', 'third', 'fourth'], index=[1, 2, 3, 4]) \n",
    "\n",
    "print(f'Item at explicit index 1 is {s.loc[1]}')\n",
    "print(f'Item at implicit index 1 is {s.iloc[1]}')\n",
    "print(s.loc[1:3])\n",
    "print(s.iloc[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using `.iloc`, the expression in `[]` can be:\n",
    "\n",
    "* an integer, a list of integers, or a slice object (e.g. `1:7`)\n",
    "* a Boolean array (see Filtering section below for why this is very useful)\n",
    "* a function with one argument (the calling object) that returns one of the above\n",
    "\n",
    "Selecing outside of the bounds of the object will raise an IndexError except when using slicing.\n",
    "\n",
    "When using `.loc`, the expression in `[]` can be:\n",
    "\n",
    "* an label, a list of labels, or a slice object with labels (e.g. `'a':'f'`; unlike normal slices the stop label is included in the slice)\n",
    "* a Boolean array\n",
    "* a function with one argument (the calling object) that returns one of the above\n",
    "\n",
    "You can use one or two dimensions in `[]` after `.loc` or `.iloc` depending on whether you want to select a subset of rows, columns, or both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `set_index` method to change the index of a DataFrame.\n",
    "\n",
    "If you want to change entries in a DataFrame selectively to some other value, you can use assignment with indexing, such as:\n",
    "\n",
    "    df.loc[row_indexer, column_indexer] = value\n",
    "    \n",
    "See the details at https://pandas.pydata.org/pandas-docs/stable/indexing.html\n",
    "    \n",
    " ## Exercise 4\n",
    " \n",
    " Use the same DataFrame from Exercise 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select just the 'animal' and 'age' columns from the DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select the data in rows [3, 5, 7] and in columns ['animal', 'age'].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a CSV into a Dataframe\n",
    "\n",
    "Use `Pandas.read_csv` to read a CSV file into a dataframe. There are many optional argumemts that you can provide, for example to set or override column headers, skip initial rows, treat first row as containing column headers, specify the type of columns (Pandas will try to infer these otherwise), skip columns, and so on. The `parse_dates` argument is especially useful for specifying which columns have date fields as Pandas doesn't infer these.\n",
    "\n",
    "Full docs are at https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://samplecsvs.s3.amazonaws.com/SacramentocrimeJanuary2006.csv',\n",
    "                 parse_dates=['cdatetime'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to do some preprocessing of a field during loading you can use the `converters` argument which takes a dictionary mapping the field names to lambda functions that munge the field. E.g. if you had a field `zip` and you wanted to take just the first 3 digits, you could use:\n",
    "\n",
    "    ..., converters={'zip': lambda x: x[:3]}, ...\n",
    "    \n",
    "You can pass a dictionary in with the `types` argument that maps field names to NumPy types, to override the type inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Spreadsheet into a DataFrame\n",
    "\n",
    "Use Pandas.read_excel to load spreadsheet data. Full details here: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.xls')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a Dataframe to a CSV or Excel spreadsheet\n",
    "\n",
    "You can use DataFrame.to_csv to write a DataFrame to a csv, and DataFrame.to_excel to save as a spreadsheet.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_excel.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting\n",
    "\n",
    "You can sort a DataFrame using the `sort_values` method:\n",
    "\n",
    "    DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, na_position='last')\n",
    "    \n",
    "The `by` argument should be a column name or list of column names in priority order (if axis=0, i.e. we are sorting the rows, which is typically the case).\n",
    "\n",
    "See https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html for the details.\n",
    "    \n",
    "\n",
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns;\n",
    "\n",
    "# Get some sample data\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A Boolean expression on a Series will return a Series of Booleans\n",
    "titanic.survived == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you index a Series with a Boolean Series, you will select the items where the index is True.\n",
    "# So:\n",
    "titanic[titanic.survived == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can combine these with & and | for and and or\n",
    "# Pandas must use these normally bitwise operators because Python allows them to be overloaded\n",
    "# while 'and' and 'or' cannot be.\n",
    "# Unfortunately as these have higher operator precedence than relational operators, the \n",
    "# subexpressions we use with them need to be enclosed in parentheses.\n",
    "\n",
    "titanic[titanic.survived & (titanic.sex == 'female') & (titanic.age > 50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Using the previous DataFrame from exercise 3, do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select only the rows where the number of visits is greater than 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select the rows where the age is missing, i.e. is NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select the rows where the animal is a cat and the age is less than 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select the rows the age is between 2 and 4 (inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the index to use this list\n",
    "idx = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the age in row 'f' to 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append a new row 'k' to df with your choice of values for each column. \n",
    "# Then delete that row to return the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the mean age for each different type of animal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count the number of each type of animal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort the data first by the values in the 'age' in decending order,\n",
    "# then by the value in the 'visit' column in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the 'animal' column, change the 'snake' entries to 'python'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The 'priority' column contains the values 'yes' and 'no'. Replace this column with a column of boolean values: \n",
    "#'yes' should be True and 'no' should be False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation\n",
    "\n",
    "`pandas.concat` can be used to concatenate Series and DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series(['A', 'B', 'C'])\n",
    "s2 = pd.Series(['D', 'E', 'F'])\n",
    "df = pd.concat([s1, s2])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the Indexes are concatenated too, so if you are using a simple row number index you can end up with duplicate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If you don't want this behavior use the `ignore_index` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively you can use `verify_integrity=True` to cause an exception to be raised if the result would have duplicate indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s2], verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame([['A1', 'B1'],['A2', 'B2']], columns=['A', 'B'])\n",
    "d2 = pd.DataFrame([['C3', 'D3'],['C4', 'D4']], columns=['A', 'B'])\n",
    "d3 = pd.DataFrame([['B1', 'C1'],['B2', 'C2']], columns=['B', 'C'])\n",
    "pd.concat([d1, d2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can join on other axis too.\n",
    "pd.concat([d1, d2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([d1, d3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If the columns are not completely shared, additional NaN entries will be made.\n",
    "pd.concat([d1, d3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can force concat to only include the columns that are shared with an inner join.\n",
    "pd.concat([d1, d3], join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html for more options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and Joining\n",
    "\n",
    "Pandas has a `merge` function that supports one-to-one, many-to-one and many-to-many joins. merge will look for matching column names between the inputs and use this as the key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame({'city': ['Seattle', 'Boston', 'New York'], 'population': [704352, 673184, 8537673]})\n",
    "d2 = pd.DataFrame({'city': ['Boston', 'New York', 'Seattle'], 'area': [48.42, 468.48, 142.5]})\n",
    "pd.merge(d1, d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can explicitly specify the column to join on; this is equivalent to the above example:\n",
    "pd.merge(d1, d2, on='city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If the column names don't match you can specify the names to use:\n",
    "d3 = pd.DataFrame({'place': ['Boston', 'New York', 'Seattle'], 'area': [48.42, 468.48, 142.5]})\n",
    "pd.merge(d1, d3, left_on='city', right_on='place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you want to drop the redundant column:\n",
    "pd.merge(d1, d3, left_on='city', right_on='place').drop('place', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`merge` joins on arbitrary columns; if you want to join on the index you can use `left_index` and `right_index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(list('ABC'), columns=['c1'])\n",
    "df2 = pd.DataFrame(list('DEF'), columns=['c2'])\n",
    "pd.merge(df1, df2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides a utility method on DataFrame, `join`, to do the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.join(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`merge` can take a `how` argument that can be `inner`, `outer`, `left` or `right` to control the type of join. `inner` joins are the default.\n",
    "\n",
    "For more info on merging see https://pandas.pydata.org/pandas-docs/stable/merging.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating and Pivot Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns;\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use unique() to see the full set of distinct values in a series\n",
    "titanic.deck.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# describe() will give summary statistics on a DataFrame. We first drop rows with NAs.\n",
    "titanic.dropna().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic.groupby('sex')['survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic.groupby(['sex', 'class'])['survived'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame result is an example of a multi-indexed DataFrame (indexed by both 'sex' and 'class'). We're mostly going to ignore those in this notebook, but it is worth noting that Pandas has an `unstack` method that can turn a mutiply-indexed DataFrame back into a conventionally-indexed one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic.groupby(['sex', 'class'])['survived'].mean().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All of the above can be achieved with a convenience pivot table method\n",
    "titanic.pivot_table('survived', index='sex', columns='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's break things down further by age group\n",
    "age = pd.cut(titanic['age'], [0, 18, 80])\n",
    "titanic.pivot_table('survived', index=['sex', age], columns='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Index and colummns are also the second and third positional arguments, so we could just use:\n",
    "titanic.pivot_table('survived', ['sex', age], 'class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Functions\n",
    "\n",
    "We saw earlier that we can add new columns to a DataFrame easily. The new column can be a function of an existing column. For example, we could add an 'is_adult' field to the Titanic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic['is_adult'] = titanic.age >= 18\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a simple case; we can do more complex row-by-row applications of arbitrary functions; here's the same change done differently (this would be much less efficient but may be the only option if the function is complex):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic['is_adult'] = titanic.apply(lambda row: row['age'] >= 18, axis=1)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Operations\n",
    "\n",
    "Pandas has vectorized string operations that will skip over missing values. You can read about them here; we wil show a few examples: https://pandas.pydata.org/pandas-docs/stable/text.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's get the more detailed Titanic data set\n",
    "df = pd.read_excel('http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.xls')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Upper-case the home.dest field\n",
    "df['home.dest'].str.upper().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's split the field up into two\n",
    "place_df = df['home.dest'].str.split('/', expand=True)  # Expands the split list into DF columns\n",
    "place_df.columns = ['home', 'dest', '']  # For some reason there is a third column\n",
    "df['home'] = place_df['home']\n",
    "df['dest'] = place_df['dest']\n",
    "df = df.drop(['home.dest'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "To see if there are missing values, we can use isnull() to get a DataFrame showing the rows that have nulls, and where they have them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.isnull().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will show us the first few rows that had null values. If we want to know which columns may have nulls, we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drop rows that have missing values, use dropna(); add `inplace=True` to do it in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case there are none - no-one could both be on a boat and be a recovered body, so at least one of these fields is always NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Plots\n",
    "\n",
    "Pandas includes the ability to do simple plots. For a Series, this typically means plotting the values in the series as the Y values, and then index as the X values; for a DataFrame this would be a multiplot. You can use `x` and `y` named arguments to select specific columns to plot, and you can use a `kind` argument to specify the type of plot.\n",
    "\n",
    "See https://pandas.pydata.org/pandas-docs/stable/visualization.html for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series([2, 3, 1, 5, 3], index=['a', 'b', 'c', 'd', 'e'])\n",
    "s.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        [2, 1],\n",
    "        [4, 4],\n",
    "        [1, 2],\n",
    "        [3, 6]\n",
    "    ],\n",
    "    index=['a', 'b', 'c', 'd'],\n",
    "    columns=['s1', 's2']\n",
    ")\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.plot(x='s1', y='s2', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charting with Seaborn\n",
    "\n",
    "See the Python Graph Gallery at https://python-graph-gallery.com/ for many examples of different types of charts including the code used to create them.\n",
    "\n",
    "There are many plotting libraries for Python; the most well known are matplotlib, seaborn (which extends matplotlib), Bokeh, and Plotly. Some offer more interactivity than others. Seaborn is a popular library so we will examine it with some examples. We first need to use the following magic to get the plots to show up in Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's get the more detailed Titanic data set\n",
    "df = pd.read_excel('http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.xls')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can use a factorplot to count categorical data\n",
    "import seaborn as sns\n",
    "sns.factorplot('sex',data=df,kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's bring class in too:\n",
    "sns.factorplot('pclass', data=df, hue='sex', kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Of course we can aggregate the other way too\n",
    "sns.factorplot('sex', data=df, hue='pclass', kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's see how many people were on each deck\n",
    "deck = pd.DataFrame(df['cabin'].dropna().str[0])\n",
    "deck.columns = ['deck']\n",
    "sns.factorplot('deck', data=deck, kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What class passenger was on each deck?\n",
    "df2 = df[['cabin', 'pclass']]\n",
    "df2 = df2.dropna()\n",
    "df2['deck'] = df2.apply(lambda row: ord(row.cabin[0]) -64, axis=1)\n",
    "\n",
    "sns.regplot(x=df2[\"pclass\"], y=df2[\"deck\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Interactivity with ipywidgets\n",
    "\n",
    "`ipywidgets` is an extension package for Jupyter that allows output cells to include interactive HTML elements. To install, you will need to run a command to enable the extension from a terminal and then restart Jupyter. First, install the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!echo y | conda install -c conda-forge ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to run this command from a terminal and restart Jupyter, then return here.\n",
    "\n",
    "    jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
    "\n",
    "We will look at a simple example using the `interact` function from `ipywidgets`. You call this giving it a function as the first argument, followed by zero or more additional arguments that can be tuples, lists or dictionaries. These arguments will each become interactive controls like sliders and drop-downs, and any change in their values will cause the function to be called again with the new values as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        [2, 1],\n",
    "        [4, 4],\n",
    "        [1, 2],\n",
    "        [3, 6]\n",
    "    ],\n",
    "    index=['a', 'b', 'c', 'd'],\n",
    "    columns=['s1', 's2']\n",
    ")\n",
    "\n",
    "\n",
    "def plot_graph(kind, col):\n",
    "    if col == 'all':\n",
    "        df.plot(kind=kind)\n",
    "    else:\n",
    "        df[col].plot(kind=kind)\n",
    "    \n",
    "\n",
    "interact(plot_graph, kind=['line', 'bar'], col=['all', 's1', 's2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See http://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html for more info on creating other types of controls when using `interact`.\n",
    "\n",
    "## Summarizing Data with pandas_profiling and facets\n",
    "\n",
    "`pandas_profiling` is a Python package that can produce much more detailed summaries of data than the `.describe()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "import seaborn as sns;\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "pandas_profiling.ProfileReport(titanic)  # You may need to run cell twice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facets is a new library from Google that looks very good. It has similar functionality to pandas_profiling as well as some powerful visualization. Installation is more complex so we won't use it now but it is worth considering.\n",
    "\n",
    "https://github.com/pair-code/facets\n",
    "\n",
    "\n",
    "## Example: Loading JSON into a DataFrame and Expanding Complex Fields\n",
    "\n",
    "In this example we'll see how we can load some structured data and process it into a flat table form better suited to machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's get some data; top stories from lobste.rs; populate a DataFrame with the JSON\n",
    "stories = pd.read_json('https://lobste.rs/hottest.json')\n",
    "stories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the \"short_id' field as the index\n",
    "stories = stories.set_index('short_id')\n",
    "\n",
    "# Show the first few rows\n",
    "stories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a look at the submitter_user field; it is a dictionary itself.\n",
    "stories.submitter_user[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We want to expand these fields into our dataframe. First expand into its own dataframe.\n",
    "user_df = stories.submitter_user.apply(pd.Series)\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We should make sure there are no collisions in column names.\n",
    "set(user_df.columns).intersection(stories.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can rename the column to avoid the clash\n",
    "user_df = user_df.rename(columns={'created_at': 'user_created_at'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now combine them, dropping the original compound column that we are expanding.\n",
    "stories = pd.concat([stories.drop(['submitter_user'], axis=1), user_df], axis=1)\n",
    "stories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The tags field is another compound field.\n",
    "stories.tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a new dataframe with the tag lists expanded into columns of Series.\n",
    "tag_df = stories.tags.apply(pd.Series)\n",
    "tag_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pivot the DataFrame\n",
    "tag_df = tag_df.stack()\n",
    "tag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Expand into a 1-hot encoding\n",
    "tag_df = pd.get_dummies(tag_df)\n",
    "tag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge multiple rows\n",
    "tag_df = tag_df.sum(level=0)\n",
    "tag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And add back to the original dataframe\n",
    "stories = pd.concat([stories.drop('tags', axis=1), tag_df], axis=1)\n",
    "stories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Baby Names\n",
    "\n",
    "The data comes from US census and is the count of names of children born in years from 1880 to 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('NationalNames.csv.zip', compression='zip')  # Pandas can unzip the data for you\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise: show the baby names from 1918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise: get the counts per year for the name 'John'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise: do the same but restrict to boys now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise: plot popularity of John as a boy's name per year\n",
    "# (hint: look at help for Seaborn barplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise - use ipywidgets.interact to create a drop-down\n",
    "# with several names and chart the selected name's popularity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
